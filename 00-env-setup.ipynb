{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f573eaae-7a82-4a2b-b4c0-4755964fd30b",
   "metadata": {},
   "source": [
    "# Environment Setup for training with TFRS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14228645-7fca-40c8-a84d-d8cfe1930af1",
   "metadata": {},
   "source": [
    "## Install Packages\n",
    "Run pip requirements.txt in either (1) the notebook cell below or (2) in a notebook terminal window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe5cd263-3dd3-4653-a53a-78a1d2ab08fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50e3697e-0f1e-415b-bc03-613743f42eb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX = ndr-v1\n"
     ]
    }
   ],
   "source": [
    "# naming convention for all cloud resources\n",
    "VERSION        = \"v1\"                  # TODO\n",
    "PREFIX         = f'ndr-{VERSION}'      # TODO\n",
    "\n",
    "print(f\"PREFIX = {PREFIX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921ebc61-1cc3-4e1f-a298-dacbd8c77051",
   "metadata": {},
   "source": [
    "## GCP project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f0ed6d9-28c1-4342-8664-b0e98526ba07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID       = myproject32549\n",
      "PROJECT_NUM      = 683169793466\n",
      "VPC_NETWORK_NAME = ucaip-haystack-vpc-network\n",
      "LOCATION         = us-central1\n",
      "REGION           = us-central1\n",
      "BQ_LOCATION      = US\n"
     ]
    }
   ],
   "source": [
    "# creds, PROJECT_ID = google.auth.default()\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "PROJECT_NUM              = !gcloud projects describe $PROJECT_ID --format=\"value(projectNumber)\"\n",
    "PROJECT_NUM              = PROJECT_NUM[0]\n",
    "\n",
    "VERTEX_SA                = f'{PROJECT_NUM}-compute@developer.gserviceaccount.com'\n",
    "\n",
    "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
    "\n",
    "# locations / regions for cloud resources\n",
    "LOCATION                 = 'us-central1'        \n",
    "REGION                   = LOCATION\n",
    "BQ_LOCATION              = 'US'\n",
    "\n",
    "print(f\"PROJECT_ID       = {PROJECT_ID}\")\n",
    "print(f\"PROJECT_NUM      = {PROJECT_NUM}\")\n",
    "print(f\"VPC_NETWORK_NAME = {VPC_NETWORK_NAME}\")\n",
    "print(f\"LOCATION         = {LOCATION}\")\n",
    "print(f\"REGION           = {REGION}\")\n",
    "print(f\"BQ_LOCATION      = {BQ_LOCATION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9bd35d9-6c0b-40b9-873c-5b137c62db33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "APP                      = 'sp'\n",
    "MODEL_TYPE               = '2tower'\n",
    "FRAMEWORK                = 'tfrs'\n",
    "DATA_VERSION             = \"v1\" # version tag for dataflow pipeline | \"v2-0-0\" # v1-0-0\n",
    "TRACK_HISTORY            = 5        # length of playlist tracks to consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2833324-082c-470d-916a-db133c2ce53d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUCKET_NAME              : ndr-v1-myproject32549-bucket\n",
      "BUCKET_URI               : gs://ndr-v1-myproject32549-bucket\n",
      "SOURCE_BUCKET            : spotify-million-playlist-dataset\n",
      "DATA_GCS_PREFIX          : data\n",
      "DATA_PATH                : gs://ndr-v1-myproject32549-bucket/data\n",
      "VOCAB_SUBDIR             : vocabs\n",
      "VOCAB_FILENAME           : vocab_dict.pkl\n",
      "CANDIDATE_PREFIX         : candidates\n",
      "TRAIN_DIR_PREFIX         : train\n",
      "VALID_DIR_PREFIX         : valid\n",
      "VPC_NETWORK_FULL         : projects/683169793466/global/networks/ucaip-haystack-vpc-network\n",
      "BQ_DATASET               : spotify_e2e_test\n",
      "BQ_TABLE_TRAIN           : train_flatten_last_5\n",
      "BQ_TABLE_VALID           : train_flatten_valid_last_5\n",
      "BQ_TABLE_CANDIDATES      : candidates\n",
      "REPO_SRC                 : src\n",
      "PIPELINES_SUB_DIR        : feature_pipes\n",
      "REPOSITORY               : ndr-v1-spotify\n",
      "IMAGE_NAME               : train-v1\n",
      "REMOTE_IMAGE_NAME        : us-central1-docker.pkg.dev/myproject32549/ndr-v1-spotify/train-v1\n",
      "DOCKERNAME               : tfrs\n",
      "SERVING_IMAGE_URI_CPU    : us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-11:latest\n",
      "SERVING_IMAGE_URI_GPU    : us-docker.pkg.dev/vertex-ai/prediction/tf2-gpu.2-11:latest\n"
     ]
    }
   ],
   "source": [
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "SOURCE_BUCKET            = 'spotify-million-playlist-dataset'\n",
    "\n",
    "# Location to write TF-Records\n",
    "DATA_GCS_PREFIX          = \"data\"\n",
    "DATA_PATH                = f\"{BUCKET_URI}/{DATA_GCS_PREFIX}\"\n",
    "VOCAB_SUBDIR             = \"vocabs\"\n",
    "VOCAB_FILENAME           = 'vocab_dict.pkl'\n",
    "\n",
    "CANDIDATE_PREFIX         = 'candidates'\n",
    "TRAIN_DIR_PREFIX         = 'train'\n",
    "VALID_DIR_PREFIX         = 'valid'\n",
    "\n",
    "VPC_NETWORK_FULL         = f\"projects/{PROJECT_NUM}/global/networks/{VPC_NETWORK_NAME}\"\n",
    "\n",
    "# BigQuery parameters\n",
    "BQ_DATASET               = 'spotify_e2e_test'\n",
    "BQ_TABLE_TRAIN           = 'train_flatten_last_5'\n",
    "BQ_TABLE_VALID           = 'train_flatten_valid_last_5'\n",
    "BQ_TABLE_CANDIDATES      = 'candidates'\n",
    "\n",
    "# repo\n",
    "REPO_SRC                 = 'src'\n",
    "PIPELINES_SUB_DIR        = 'feature_pipes'\n",
    "\n",
    "# container registry\n",
    "REPOSITORY               = f'{PREFIX}-spotify'\n",
    "IMAGE_NAME               = f'train-{VERSION}'\n",
    "REMOTE_IMAGE_NAME        = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE_NAME}\"\n",
    "DOCKERNAME               = f'tfrs'\n",
    "\n",
    "# serving images\n",
    "SERVING_IMAGE_URI_CPU    = 'us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-11:latest'\n",
    "SERVING_IMAGE_URI_GPU    = 'us-docker.pkg.dev/vertex-ai/prediction/tf2-gpu.2-11:latest'\n",
    "\n",
    "print(f\"BUCKET_NAME              : {BUCKET_NAME}\")\n",
    "print(f\"BUCKET_URI               : {BUCKET_URI}\")\n",
    "print(f\"SOURCE_BUCKET            : {SOURCE_BUCKET}\")\n",
    "\n",
    "print(f\"DATA_GCS_PREFIX          : {DATA_GCS_PREFIX}\")\n",
    "print(f\"DATA_PATH                : {DATA_PATH}\")\n",
    "print(f\"VOCAB_SUBDIR             : {VOCAB_SUBDIR}\")\n",
    "print(f\"VOCAB_FILENAME           : {VOCAB_FILENAME}\")\n",
    "\n",
    "print(f\"CANDIDATE_PREFIX         : {CANDIDATE_PREFIX}\")\n",
    "print(f\"TRAIN_DIR_PREFIX         : {TRAIN_DIR_PREFIX}\")\n",
    "print(f\"VALID_DIR_PREFIX         : {VALID_DIR_PREFIX}\")\n",
    "\n",
    "print(f\"VPC_NETWORK_FULL         : {VPC_NETWORK_FULL}\")\n",
    "\n",
    "print(f\"BQ_DATASET               : {BQ_DATASET}\")\n",
    "print(f\"BQ_TABLE_TRAIN           : {BQ_TABLE_TRAIN}\")\n",
    "print(f\"BQ_TABLE_VALID           : {BQ_TABLE_VALID}\")\n",
    "print(f\"BQ_TABLE_CANDIDATES      : {BQ_TABLE_CANDIDATES}\")\n",
    "\n",
    "print(f\"REPO_SRC                 : {REPO_SRC}\")\n",
    "print(f\"PIPELINES_SUB_DIR        : {PIPELINES_SUB_DIR}\")\n",
    "\n",
    "print(f\"REPOSITORY               : {REPOSITORY}\")\n",
    "print(f\"IMAGE_NAME               : {IMAGE_NAME}\")\n",
    "print(f\"REMOTE_IMAGE_NAME        : {REMOTE_IMAGE_NAME}\")\n",
    "print(f\"DOCKERNAME               : {DOCKERNAME}\")\n",
    "\n",
    "print(f\"SERVING_IMAGE_URI_CPU    : {SERVING_IMAGE_URI_CPU}\")\n",
    "print(f\"SERVING_IMAGE_URI_GPU    : {SERVING_IMAGE_URI_GPU}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c9aeab8-73aa-4503-b91b-3ab7902596b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://ndr-v1-myproject32549-bucket/...\n",
      "ServiceException: 409 A Cloud Storage bucket named 'ndr-v1-myproject32549-bucket' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"
     ]
    }
   ],
   "source": [
    "# create bucket\n",
    "! gsutil mb -l $REGION $BUCKET_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c69c1a3-ee9a-4b94-b67a-f38b05b60eef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! gsutil iam ch serviceAccount:{VERTEX_SA}:roles/storage.objects.get $BUCKET_URI\n",
    "# ! gsutil iam ch serviceAccount:{VERTEX_SA}:roles/storage.objects.get $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b568458-212c-49c9-8ac8-0b7443cb6019",
   "metadata": {},
   "source": [
    "## Save Notebook Configuration Data\n",
    "If you want to avoid having to re-enter these across notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01b46ec0-998e-42f2-8aa2-ec907ec2838c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"myproject32549\"\n",
      "PROJECT_NUM              = \"683169793466\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"683169793466-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"ndr-v1\"\n",
      "VERSION                  = \"v1\"\n",
      "\n",
      "APP                      = \"sp\"\n",
      "MODEL_TYPE               = \"2tower\"\n",
      "FRAMEWORK                = \"tfrs\"\n",
      "DATA_VERSION             = \"v1\"\n",
      "TRACK_HISTORY            = \"5\"\n",
      "\n",
      "BUCKET_NAME              = \"ndr-v1-myproject32549-bucket\"\n",
      "BUCKET_URI               = \"gs://ndr-v1-myproject32549-bucket\"\n",
      "SOURCE_BUCKET            = \"spotify-million-playlist-dataset\"\n",
      "\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://ndr-v1-myproject32549-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "CANDIDATE_PREFIX         = \"candidates\"\n",
      "TRAIN_DIR_PREFIX         = \"train\"\n",
      "VALID_DIR_PREFIX         = \"valid\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/683169793466/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BQ_DATASET               = \"spotify_e2e_test\"\n",
      "BQ_TABLE_TRAIN           = \"train_flatten_last_5\"\n",
      "BQ_TABLE_VALID           = \"train_flatten_valid_last_5\"\n",
      "BQ_TABLE_CANDIDATES      = \"candidates\"\n",
      "\n",
      "REPO_SRC                 = \"src\"\n",
      "PIPELINES_SUB_DIR        = \"feature_pipes\"\n",
      "\n",
      "REPOSITORY               = \"ndr-v1-spotify\"\n",
      "IMAGE_NAME               = \"train-v1\"\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/myproject32549/ndr-v1-spotify/train-v1\"\n",
      "DOCKERNAME               = \"tfrs\"\n",
      "\n",
      "SERVING_IMAGE_URI_CPU    = \"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-11:latest\"\n",
      "SERVING_IMAGE_URI_GPU    = \"us-docker.pkg.dev/vertex-ai/prediction/tf2-gpu.2-11:latest\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = f\"\"\"\n",
    "PROJECT_ID               = \\\"{PROJECT_ID}\\\"\n",
    "PROJECT_NUM              = \\\"{PROJECT_NUM}\\\"\n",
    "LOCATION                 = \\\"{LOCATION}\\\"\n",
    "\n",
    "REGION                   = \\\"{REGION}\\\"\n",
    "BQ_LOCATION              = \\\"{BQ_LOCATION}\\\"\n",
    "VPC_NETWORK_NAME         = \\\"{VPC_NETWORK_NAME}\\\"\n",
    "\n",
    "VERTEX_SA                = \\\"{VERTEX_SA}\\\"\n",
    "\n",
    "PREFIX                   = \\\"{PREFIX}\\\"\n",
    "VERSION                  = \\\"{VERSION}\\\"\n",
    "\n",
    "APP                      = \\\"{APP}\\\"\n",
    "MODEL_TYPE               = \\\"{MODEL_TYPE}\\\"\n",
    "FRAMEWORK                = \\\"{FRAMEWORK}\\\"\n",
    "DATA_VERSION             = \\\"{DATA_VERSION}\\\"\n",
    "TRACK_HISTORY            = \\\"{TRACK_HISTORY}\\\"\n",
    "\n",
    "BUCKET_NAME              = \\\"{BUCKET_NAME}\\\"\n",
    "BUCKET_URI               = \\\"{BUCKET_URI}\\\"\n",
    "SOURCE_BUCKET            = \\\"{SOURCE_BUCKET}\\\"\n",
    "\n",
    "DATA_GCS_PREFIX          = \\\"{DATA_GCS_PREFIX}\\\"\n",
    "DATA_PATH                = \\\"{DATA_PATH}\\\"\n",
    "VOCAB_SUBDIR             = \\\"{VOCAB_SUBDIR}\\\"\n",
    "VOCAB_FILENAME           = \\\"{VOCAB_FILENAME}\\\"\n",
    "\n",
    "CANDIDATE_PREFIX         = \\\"{CANDIDATE_PREFIX}\\\"\n",
    "TRAIN_DIR_PREFIX         = \\\"{TRAIN_DIR_PREFIX}\\\"\n",
    "VALID_DIR_PREFIX         = \\\"{VALID_DIR_PREFIX}\\\"\n",
    "\n",
    "VPC_NETWORK_FULL         = \\\"{VPC_NETWORK_FULL}\\\"\n",
    "\n",
    "BQ_DATASET               = \\\"{BQ_DATASET}\\\"\n",
    "BQ_TABLE_TRAIN           = \\\"{BQ_TABLE_TRAIN}\\\"\n",
    "BQ_TABLE_VALID           = \\\"{BQ_TABLE_VALID}\\\"\n",
    "BQ_TABLE_CANDIDATES      = \\\"{BQ_TABLE_CANDIDATES}\\\"\n",
    "\n",
    "REPO_SRC                 = \\\"{REPO_SRC}\\\"\n",
    "PIPELINES_SUB_DIR        = \\\"{PIPELINES_SUB_DIR}\\\"\n",
    "\n",
    "REPOSITORY               = \\\"{REPOSITORY}\\\"\n",
    "IMAGE_NAME               = \\\"{IMAGE_NAME}\\\"\n",
    "REMOTE_IMAGE_NAME        = \\\"{REMOTE_IMAGE_NAME}\\\"\n",
    "DOCKERNAME               = \\\"{DOCKERNAME}\\\"\n",
    "\n",
    "SERVING_IMAGE_URI_CPU    = \\\"{SERVING_IMAGE_URI_CPU}\\\"\n",
    "SERVING_IMAGE_URI_GPU    = \\\"{SERVING_IMAGE_URI_GPU}\\\"\n",
    "\"\"\"\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87901338-bccd-41f0-8aeb-edad2b0a91f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying from <STDIN>...\n",
      "/ [1 files][    0.0 B/    0.0 B]                                                \n",
      "Operation completed over 1 objects.                                              \n"
     ]
    }
   ],
   "source": [
    "!echo '{config}' | gsutil cp - {BUCKET_URI}/config/notebook_env.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cad49778-eb36-4b20-9201-3a266a97dbc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ndr-v1-myproject32549-bucket/config/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c481f5a2-7006-41f7-b111-edc4f0d722c3",
   "metadata": {},
   "source": [
    "## Create BigQuery Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bd8fc8c-4965-48bc-96aa-335c8a165ae0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from google.cloud import bigquery\n",
    "\n",
    "bigquery_client = bigquery.Client(project=PROJECT_ID, location=BQ_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f5db076-2b7c-40c9-826d-da91c53e00a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "Conflict",
     "evalue": "409 POST https://bigquery.googleapis.com/bigquery/v2/projects/myproject32549/datasets?prettyPrint=false: Already Exists: Dataset myproject32549:spotify_e2e_test",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConflict\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m dataset\u001b[38;5;241m.\u001b[39mlocation \u001b[38;5;241m=\u001b[39m BQ_LOCATION\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Send the dataset to the API for creation, with an explicit timeout.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Raises google.api_core.exceptions.Conflict if the Dataset already\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# exists within the project.\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mbigquery_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBQ_DATASET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Make an API request.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated dataset \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(bigquery_client\u001b[38;5;241m.\u001b[39mproject, dataset\u001b[38;5;241m.\u001b[39mdataset_id))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/client.py:681\u001b[0m, in \u001b[0;36mClient.create_dataset\u001b[0;34m(self, dataset, exists_ok, retry, timeout)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     span_attributes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: path}\n\u001b[0;32m--> 681\u001b[0m     api_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspan_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBigQuery.createDataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspan_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspan_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39mfrom_api_repr(api_response)\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core_exceptions\u001b[38;5;241m.\u001b[39mConflict:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/client.py:831\u001b[0m, in \u001b[0;36mClient._call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m create_span(\n\u001b[1;32m    829\u001b[0m         name\u001b[38;5;241m=\u001b[39mspan_name, attributes\u001b[38;5;241m=\u001b[39mspan_attributes, client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, job_ref\u001b[38;5;241m=\u001b[39mjob_ref\n\u001b[1;32m    830\u001b[0m     ):\n\u001b[0;32m--> 831\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/_http/__init__.py:494\u001b[0m, in \u001b[0;36mJSONConnection.api_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    482\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    483\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    484\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m     extra_api_info\u001b[38;5;241m=\u001b[39mextra_api_info,\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_http_response(response)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expect_json \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[0;31mConflict\u001b[0m: 409 POST https://bigquery.googleapis.com/bigquery/v2/projects/myproject32549/datasets?prettyPrint=false: Already Exists: Dataset myproject32549:spotify_e2e_test"
     ]
    }
   ],
   "source": [
    "# Create a bigquery dataset (one time operation)\n",
    "# Construct a full Dataset object to send to the API.\n",
    "dataset = bigquery.Dataset(f\"`{PROJECT_ID}.{BQ_DATASET}`\")\n",
    "\n",
    "# TODO(developer): Specify the geographic location where the dataset should reside.\n",
    "dataset.location = BQ_LOCATION\n",
    "\n",
    "# Send the dataset to the API for creation, with an explicit timeout.\n",
    "# Raises google.api_core.exceptions.Conflict if the Dataset already\n",
    "# exists within the project.\n",
    "dataset = bigquery_client.create_dataset(BQ_DATASET, timeout=30)  # Make an API request.\n",
    "print(\"Created dataset {}.{}\".format(bigquery_client.project, dataset.dataset_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e9ba87-e422-487b-8f81-fbf50aeb53e7",
   "metadata": {},
   "source": [
    "## gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5ce181-7f8a-43c2-b292-7d4a52e22adc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile .gitignore\n",
    "__init__.cpython*\n",
    "candidate_pipeline.cypthon*\n",
    "*.cpython-310.pyc\n",
    "*.cpython-37.pyc\n",
    "*-checkpoint.py*\n",
    "*.ipynb_checkpoints\n",
    "*.ipynb_checkpoints/*\n",
    ".tensorboard-*\n",
    "*WIP*\n",
    "*ARCHIVED*\n",
    "# .gcloudignore\n",
    "# .git\n",
    ".github\n",
    "*__pycache__\n",
    "*cpython-37.pyc\n",
    ".gitignore\n",
    ".DS_Store\n",
    "\n",
    "# Pyhon byte-compiled / optimized files\n",
    "__pycache__/\n",
    "*.py[cod]\n",
    "*$py.class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c9896e-62c4-470f-8cad-8ed4b646eac3",
   "metadata": {},
   "source": [
    "### Delete `__pycache__` directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d69e358-638b-4e79-9c0f-51ae7a65d5a8",
   "metadata": {},
   "source": [
    "First run `LIST_CMD` to validate query results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e28457c2-43a9-4e38-ac59-9766e816f45b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy these commands into terminal:\n",
      "\n",
      "find . | grep -E \"(/__pycache__$|\\.pyc$|\\.pyo$)\"\n",
      "find . | grep -E \"(/__pycache__$|\\.pyc$|\\.pyo$)\" | xargs rm -rf\n"
     ]
    }
   ],
   "source": [
    "LIST_CMD = 'find . | grep -E \"(/__pycache__$|\\.pyc$|\\.pyo$)\"'\n",
    "DELETE_CMD = 'find . | grep -E \"(/__pycache__$|\\.pyc$|\\.pyo$)\" | xargs rm -rf'\n",
    "\n",
    "# set variables if running in terminal\n",
    "print(\"copy these commands into terminal:\\n\")\n",
    "print(f\"{LIST_CMD}\")\n",
    "print(f\"{DELETE_CMD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9bd126-56db-4821-847b-49b8f4949449",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-8:m119"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
