{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1df6c870-747a-44c2-854e-bcd5ed14f320",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Beam conversion from Bigquery to TF Records\n",
    "\n",
    "In this notebook we use Apache Beam to convert to tfrecords\n",
    "The applications can be found in `beam_candidates` and `beam_training` for candidate generation and training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c84b0f-ecdd-4df2-b239-ce7ad8388851",
   "metadata": {},
   "source": [
    "## Load env config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adc9bcee-090a-45b6-89b6-8d7bffc6f34e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX = ndr-v1\n"
     ]
    }
   ],
   "source": [
    "# naming convention for all cloud resources\n",
    "VERSION        = \"v1\"                  # TODO\n",
    "PREFIX         = f'ndr-{VERSION}'      # TODO\n",
    "\n",
    "print(f\"PREFIX = {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0318a52-85f7-48de-a7d3-483c199df4fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"myproject32549\"\n",
      "PROJECT_NUM              = \"683169793466\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"683169793466-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"ndr-v1\"\n",
      "VERSION                  = \"v1\"\n",
      "\n",
      "APP                      = \"sp\"\n",
      "MODEL_TYPE               = \"2tower\"\n",
      "FRAMEWORK                = \"tfrs\"\n",
      "DATA_VERSION             = \"v1\"\n",
      "TRACK_HISTORY            = \"5\"\n",
      "\n",
      "BUCKET_NAME              = \"ndr-v1-myproject32549-bucket\"\n",
      "BUCKET_URI               = \"gs://ndr-v1-myproject32549-bucket\"\n",
      "SOURCE_BUCKET            = \"spotify-million-playlist-dataset\"\n",
      "\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://ndr-v1-myproject32549-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "CANDIDATE_PREFIX         = \"candidates\"\n",
      "TRAIN_DIR_PREFIX         = \"train\"\n",
      "VALID_DIR_PREFIX         = \"valid\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/683169793466/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BQ_DATASET               = \"spotify_e2e_test\"\n",
      "BQ_TABLE_TRAIN           = \"train_flatten_last_5\"\n",
      "BQ_TABLE_VALID           = \"train_flatten_valid_last_5\"\n",
      "BQ_TABLE_CANDIDATES      = \"candidates\"\n",
      "\n",
      "REPO_SRC                 = \"src\"\n",
      "PIPELINES_SUB_DIR        = \"feature_pipes\"\n",
      "\n",
      "REPOSITORY               = \"ndr-v1-spotify\"\n",
      "IMAGE_NAME               = \"train-v1\"\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/myproject32549/ndr-v1-spotify/train-v1\"\n",
      "DOCKERNAME               = \"tfrs\"\n",
      "\n",
      "SERVING_IMAGE_URI_CPU    = \"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-11:latest\"\n",
      "SERVING_IMAGE_URI_GPU    = \"us-docker.pkg.dev/vertex-ai/prediction/tf2-gpu.2-11:latest\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8581f1ce-ccb5-4b3d-b683-c3d35ad01762",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spotify_e2e_test'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BQ_DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5856e02-89a9-4237-8ada-bdd639e4af65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 gs://ndr-v1-myproject32549-bucket/config/\n",
      "                                 gs://ndr-v1-myproject32549-bucket/data/\n",
      "                                 gs://ndr-v1-myproject32549-bucket/local-train-v2/\n",
      "                                 gs://ndr-v1-myproject32549-bucket/matching_engine/\n",
      "                                 gs://ndr-v1-myproject32549-bucket/scale-training-v1/\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls -al gs://$BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79bd23b-7d91-463e-bf10-adeb318169e3",
   "metadata": {},
   "source": [
    "## pip & package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bab01ef-6f4f-47fe-8f54-56bae24cae25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade 'apache-beam[gcp]' --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3148ce99-d7d0-4298-a3d3-4ea5a1aee30b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5227d2ae-c04a-4ae7-b61a-d65233a80f14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "storage_client = storage.Client(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6babbe19-0ea7-42cc-ac89-db2705f4ae16",
   "metadata": {},
   "source": [
    "# Run Dataflow to convert BQ to TFrecords\n",
    "\n",
    "Candidate generation can be found in `beam_candidates`\n",
    "Training and Validation generation can be found in `beam_training`\n",
    "\n",
    "Usage:\n",
    "* Candidate generation\n",
    "\n",
    "> `beam_candidates\\python3 main.py $PROJECT_ID $NETWORK $REGION $VERSION $BUCKET_NAME $CANDIDATE_PREFIX $BQ_DATASET $BQ_TABLE_CANDIDATES`\n",
    "   \n",
    "* Training generation\n",
    "  \n",
    "> `beam_training\\python3 main-train.py <BQ_table> <gcs data subfolder> <desired partition size MB> <BQ dataset size MB> <version tag>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8b0304b-3da3-45f7-831d-413d2d248b48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mbeam_training\u001b[00m\n",
      "├── README.MD\n",
      "├── __init__.py\n",
      "├── \u001b[01;34mcreate_tfrecords_training.egg-info\u001b[00m\n",
      "│   ├── PKG-INFO\n",
      "│   ├── SOURCES.txt\n",
      "│   ├── dependency_links.txt\n",
      "│   ├── requires.txt\n",
      "│   └── top_level.txt\n",
      "├── main-train.py\n",
      "├── setup.py\n",
      "└── \u001b[01;34mtrain_pipeline\u001b[00m\n",
      "    ├── __init__.py\n",
      "    ├── \u001b[01;34m__pycache__\u001b[00m\n",
      "    │   ├── __init__.cpython-310.pyc\n",
      "    │   ├── __init__.cpython-37.pyc\n",
      "    │   ├── train_pipe.cpython-37.pyc\n",
      "    │   └── train_pipe_shape.cpython-310.pyc\n",
      "    └── train_pipe_shape.py\n",
      "\n",
      "3 directories, 15 files\n"
     ]
    }
   ],
   "source": [
    "!tree beam_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81357053-6541-4fd2-8e04-b96474b797b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/spotify_mpd_two_tower/beam_training\n"
     ]
    }
   ],
   "source": [
    "%cd beam_training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f274a5c-7f9a-4842-8aa4-d4f336937797",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myproject32549 ucaip-haystack-vpc-network us-central1 v1 ndr-v1-myproject32549-bucket candidates spotify_e2e_test candidates\n"
     ]
    }
   ],
   "source": [
    "!echo $PROJECT_ID $VPC_NETWORK_NAME $REGION $DATA_VERSION $BUCKET_NAME $CANDIDATE_PREFIX $BQ_DATASET $BQ_TABLE_CANDIDATES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e55b2d-4533-4329-97e7-4e175db2a7bd",
   "metadata": {},
   "source": [
    "### Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0953936-a39a-4d2e-8ba1-2b57d045b7c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# VPC_NETWORK_NAME=\"default\"\n",
    "BQ_DATASET = 'spotify_e2e_test2'\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"VPC_NETWORK_NAME:\", VPC_NETWORK_NAME)\n",
    "\n",
    "! python3 main.py $PROJECT_ID $VPC_NETWORK_NAME $REGION $DATA_VERSION $BUCKET_NAME $CANDIDATE_PREFIX $BQ_DATASET $BQ_TABLE_CANDIDATES\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"total runtime_mins: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3af313-e958-4e62-ac0a-8482dc8763c4",
   "metadata": {},
   "source": [
    "### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a44dce0b-c3c7-4ad7-b243-995766ec5e1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/spotify_mpd_two_tower/beam_training\n"
     ]
    }
   ],
   "source": [
    "%cd ../beam_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c23e4e85-b611-42f1-b8e5-023ffb49919e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REGION='asia-east1'\n",
    "\n",
    "TARGET_SHARD_SIZE_MB_VALID = 250\n",
    "TOTAL_MB_VALID = 500\n",
    "NUM_TF_RECORDS = int(TOTAL_MB_VALID) // int(TARGET_SHARD_SIZE_MB_VALID)\n",
    "NUM_TF_RECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f16dfa6-6c77-4d9d-b2cd-cf9ea2f6d9b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myproject32549 ucaip-haystack-vpc-network asia-east1 v1 ndr-v1-myproject32549-bucket valid 500 250 spotify_e2e_test train_flatten_valid_last_5\n"
     ]
    }
   ],
   "source": [
    "! echo $PROJECT_ID $VPC_NETWORK_NAME $REGION $DATA_VERSION $BUCKET_NAME $VALID_DIR_PREFIX $TOTAL_MB_VALID $TARGET_SHARD_SIZE_MB_VALID $BQ_DATASET $BQ_TABLE_VALID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c85ef22a-7aa2-419d-b9e1-78a13a842489",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Expected TFRecords: 2\n",
      "GoogleCloudOptions(create_from_snapshot=None, dataflow_endpoint=https://dataflow.googleapis.com, dataflow_kms_key=None, dataflow_service_options=None, enable_artifact_caching=False, enable_hot_key_logging=False, enable_streaming_engine=False, flexrs_goal=None, gcp_oauth_scopes=['https://www.googleapis.com/auth/bigquery', 'https://www.googleapis.com/auth/cloud-platform', 'https://www.googleapis.com/auth/devstorage.full_control', 'https://www.googleapis.com/auth/userinfo.email', 'https://www.googleapis.com/auth/datastore', 'https://www.googleapis.com/auth/spanner.admin', 'https://www.googleapis.com/auth/spanner.data'], impersonate_service_account=None, job_name=spotify-bq-tfrecords-v1-240422-175517, labels=None, no_auth=False, project=myproject32549, region=asia-east1, service_account_email=None, staging_location=gs://ndr-v1-myproject32549-bucket/data/v1/job/staging/, temp_location=gs://ndr-v1-myproject32549-bucket/data/v1/job/temp/, template_location=None, transform_name_mapping=None, update=False)\n",
      "/opt/conda/bin/python3: No module named build\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "total runtime_mins: 7\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "BQ_DATASET = 'spotify_e2e_test2'\n",
    "\n",
    "! python3 main-train.py $PROJECT_ID $VPC_NETWORK_NAME $REGION $DATA_VERSION $BUCKET_NAME $VALID_DIR_PREFIX $TOTAL_MB_VALID $TARGET_SHARD_SIZE_MB_VALID $BQ_DATASET $BQ_TABLE_VALID\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"total runtime_mins: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5c97d0-3518-45b0-a72f-10ac9f8007ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tain set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9896f5e7-975c-441c-99a2-2f19fa444910",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_SHARD_SIZE_MB_TRAIN = 2000\n",
    "TOTAL_MB_TRAIN = 44_000\n",
    "NUM_TF_RECORDS = int(TOTAL_MB_TRAIN) // int(TARGET_SHARD_SIZE_MB_TRAIN)\n",
    "NUM_TF_RECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fca57657-de45-4b03-b3f9-896c4c2f1a3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myproject32549 ucaip-haystack-vpc-network asia-east1 v1 ndr-v1-myproject32549-bucket train 44000 2000 spotify_e2e_test train_flatten_last_5\n"
     ]
    }
   ],
   "source": [
    "!echo $PROJECT_ID $VPC_NETWORK_NAME $REGION $DATA_VERSION $BUCKET_NAME $TRAIN_DIR_PREFIX $TOTAL_MB_TRAIN $TARGET_SHARD_SIZE_MB_TRAIN $BQ_DATASET $BQ_TABLE_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ff4949c-f506-4a2c-9b74-3ccce77c243e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Expected TFRecords: 22\n",
      "GoogleCloudOptions(create_from_snapshot=None, dataflow_endpoint=https://dataflow.googleapis.com, dataflow_kms_key=None, dataflow_service_options=None, enable_artifact_caching=False, enable_hot_key_logging=False, enable_streaming_engine=False, flexrs_goal=None, gcp_oauth_scopes=['https://www.googleapis.com/auth/bigquery', 'https://www.googleapis.com/auth/cloud-platform', 'https://www.googleapis.com/auth/devstorage.full_control', 'https://www.googleapis.com/auth/userinfo.email', 'https://www.googleapis.com/auth/datastore', 'https://www.googleapis.com/auth/spanner.admin', 'https://www.googleapis.com/auth/spanner.data'], impersonate_service_account=None, job_name=spotify-bq-tfrecords-v1-240422-180304, labels=None, no_auth=False, project=myproject32549, region=asia-east1, service_account_email=None, staging_location=gs://ndr-v1-myproject32549-bucket/data/v1/job/staging/, temp_location=gs://ndr-v1-myproject32549-bucket/data/v1/job/temp/, template_location=None, transform_name_mapping=None, update=False)\n",
      "/opt/conda/bin/python3: No module named build\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "total runtime_mins: 7\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "! python3 main-train.py $PROJECT_ID $VPC_NETWORK_NAME $REGION $DATA_VERSION $BUCKET_NAME $TRAIN_DIR_PREFIX $TOTAL_MB_TRAIN $TARGET_SHARD_SIZE_MB_TRAIN $BQ_DATASET $BQ_TABLE_TRAIN\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"total runtime_mins: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a98829e-7498-4998-9aff-aa996a8f7c11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/spotify_mpd_two_tower\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a33f54-c717-4130-b375-3108836e9e04",
   "metadata": {},
   "source": [
    "# Test TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d190ac1-1a81-4f64-8c24-8a5405f19830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from util import feature_set_utils as feature_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7185e13d-9985-40ae-8b1a-3a9d06487bcb",
   "metadata": {},
   "source": [
    "## Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fccb4df-a503-4b56-95e6-7af42dd2453e",
   "metadata": {},
   "source": [
    "### Candidate tower features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36de4fc9-1a3c-44f7-bf9b-7e7e9d86bbbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'track_uri_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'track_name_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'artist_uri_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'artist_name_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'album_uri_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'album_name_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'duration_ms_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_pop_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'artist_pop_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'artist_genres_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'artist_followers_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_danceability_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_energy_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_key_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'track_loudness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_mode_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'track_speechiness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_acousticness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_instrumentalness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_liveness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_valence_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_tempo_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_time_signature_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_features = feature_utils.get_candidate_features()\n",
    "candidate_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9eb2d9-a81a-4c94-bd70-26eb605037ab",
   "metadata": {},
   "source": [
    "### Candidate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c7c9dd2-7b32-4cb9-a7f9-97a0b1cdd487",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_files:  ['gs://ndr-v1-myproject32549-bucket/data/v1/candidates/-00000-of-00001.tfrecords']\n"
     ]
    }
   ],
   "source": [
    "candidate_files = []\n",
    "\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'data/{DATA_VERSION}/{CANDIDATE_PREFIX}'):\n",
    "    candidate_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "print(\"candidate_files: \", candidate_files)\n",
    "candidate_dataset = tf.data.TFRecordDataset(candidate_files)\n",
    "\n",
    "parsed_candidate_dataset = candidate_dataset.map(feature_utils.parse_candidate_tfrecord_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b57c12cb-6c95-4bac-ba29-4d389babc44c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Pihana'], dtype=object)>,\n",
      " 'album_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:album:4f3ZzEECOPykndvzaLlcg0'], dtype=object)>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'NONE'], dtype=object)>,\n",
      " 'artist_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Napua'], dtype=object)>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:artist:3411tg52DNMfAuJiwZIfjW'], dtype=object)>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([219346.], dtype=float32)>,\n",
      " 'track_acousticness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.917], dtype=float32)>,\n",
      " 'track_danceability_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.485], dtype=float32)>,\n",
      " 'track_energy_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.298], dtype=float32)>,\n",
      " 'track_instrumentalness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
      " 'track_key_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'5.0'], dtype=object)>,\n",
      " 'track_liveness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0959], dtype=float32)>,\n",
      " 'track_loudness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-8.169], dtype=float32)>,\n",
      " 'track_mode_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'0'], dtype=object)>,\n",
      " 'track_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Lovely Sunrise Haleakala'], dtype=object)>,\n",
      " 'track_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([3.], dtype=float32)>,\n",
      " 'track_speechiness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0265], dtype=float32)>,\n",
      " 'track_tempo_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([98.038], dtype=float32)>,\n",
      " 'track_time_signature_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'4'], dtype=object)>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:track:1C1E8m6yt6TzNzpio00Kci'], dtype=object)>,\n",
      " 'track_valence_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.197], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for x in parsed_candidate_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973f835e-fb68-4610-92a5-3f4c9547923d",
   "metadata": {},
   "source": [
    "## Train & Valid datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b519ecc-fae8-4a9e-9f89-303c7f24e107",
   "metadata": {},
   "source": [
    "### Get all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2cb3949-bc40-4aab-a99d-aed5ec680832",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRACK_HISTORY:  5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'track_uri_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'track_name_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'artist_uri_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'artist_name_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'album_uri_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'album_name_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'duration_ms_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_pop_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'artist_pop_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'artist_genres_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'artist_followers_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_danceability_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_energy_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_key_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'track_loudness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_mode_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'track_speechiness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_acousticness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_instrumentalness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_liveness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_valence_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_tempo_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_time_signature_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'pl_name_src': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'pl_collaborative_src': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'pl_duration_ms_new': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'num_pl_songs_new': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'num_pl_artists_new': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'num_pl_albums_new': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_uri_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'track_name_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'artist_uri_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'artist_name_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'album_uri_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'album_name_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'artist_genres_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'duration_ms_songs_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_pop_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'artist_pop_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'artists_followers_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_danceability_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_energy_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_key_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'track_loudness_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_mode_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'track_speechiness_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_acousticness_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_instrumentalness_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_liveness_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_valence_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_tempo_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_time_signature_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'candidate_rank': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"TRACK_HISTORY: \", TRACK_HISTORY)\n",
    "feats = feature_utils.get_all_features(TRACK_HISTORY, ranker=True)\n",
    "feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6975cd65-6d6f-412c-8154-41f6041b381a",
   "metadata": {},
   "source": [
    "### Choose feature set mappings\n",
    "\n",
    "> TODO: define mappings\n",
    "\n",
    "* `towers`\n",
    "* `rank`\n",
    "* `audio-rank`\n",
    "* `lw-audio-rank`\n",
    "\n",
    "```python\n",
    "def get_feature_mapping(key):\n",
    "    \"\"\"\n",
    "    returns chosen parse function\n",
    "    \n",
    "    example:\n",
    "        desired_mapping = get_feature_mapping(MY_CHOICE)\n",
    "    \"\"\"\n",
    "    \n",
    "    map_dict = {\n",
    "        \"towers\": feature_utils.parse_towers_tfrecord,\n",
    "        \"rank\": feature_utils.parse_rank_tfrecord,\n",
    "        \"audio-rank\": feature_utils.parse_audio_rank_tfrecord,\n",
    "        \"lw-audio-rank\": feature_utils.parse_lw_audio_rank_tfrecord,\n",
    "    }\n",
    "    return map_dict[key]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d61b0-9f70-48c4-b2ec-c682f4a7c034",
   "metadata": {},
   "source": [
    "### Valid files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a500213-a3e4-46c3-a0d7-24452eaa80ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function util.feature_set_utils.parse_rank_tfrecord(example)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURE_MAP = feature_utils.parse_rank_tfrecord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bdad96f5-0e70-427b-9525-081406b9c80f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_files:  ['gs://ndr-v1-myproject32549-bucket/data/v1/valid/-00000-of-00002.tfrecords', 'gs://ndr-v1-myproject32549-bucket/data/v1/valid/-00001-of-00002.tfrecords']\n",
      "valid size: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec={'album_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'album_name_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'album_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'album_uri_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artist_followers_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'artist_genres_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_genres_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artist_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_name_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artist_pop_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'artist_pop_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'artist_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_uri_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artists_followers_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'candidate_rank': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'duration_ms_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'duration_ms_songs_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'num_pl_albums_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'num_pl_artists_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'num_pl_songs_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'pl_collaborative_src': TensorSpec(shape=(), dtype=tf.string, name=None), 'pl_duration_ms_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'pl_name_src': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_acousticness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_acousticness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_danceability_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_danceability_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_energy_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_energy_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_instrumentalness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_instrumentalness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_key_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_key_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_liveness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_liveness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_loudness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_loudness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_mode_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_mode_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_name_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_pop_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_pop_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_speechiness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_speechiness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_tempo_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_tempo_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_time_signature_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_time_signature_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_uri_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_valence_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_valence_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_files = []\n",
    "\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'data/{DATA_VERSION}/{VALID_DIR_PREFIX}/'):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        valid_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "print(\"valid_files: \", valid_files)\n",
    "\n",
    "valid = tf.data.TFRecordDataset(valid_files)\n",
    "\n",
    "print(f\"valid size: {len(list(valid))}\")\n",
    "\n",
    "valid_parsed = valid.map(FEATURE_MAP)\n",
    "valid_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6b87491-5706-4204-a19e-582612c1b439",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Tiller Gang'], dtype=object)>,\n",
      " 'album_name_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'Tiller Gang', b'Tiller Gang', b'Tiller Gang', b'Tiller Gang',\n",
      "        b'Tiller Gang']], dtype=object)>,\n",
      " 'album_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:album:0NJcvtv173uUae6NFosCIl'], dtype=object)>,\n",
      " 'album_uri_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'spotify:album:0NJcvtv173uUae6NFosCIl',\n",
      "        b'spotify:album:0NJcvtv173uUae6NFosCIl',\n",
      "        b'spotify:album:0NJcvtv173uUae6NFosCIl',\n",
      "        b'spotify:album:0NJcvtv173uUae6NFosCIl',\n",
      "        b'spotify:album:0NJcvtv173uUae6NFosCIl']], dtype=object)>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([190565.], dtype=float32)>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"'country rap', 'redneck'\"], dtype=object)>,\n",
      " 'artist_genres_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b\"'country rap', 'redneck'\", b\"'country rap', 'redneck'\",\n",
      "        b\"'country rap', 'redneck'\", b\"'country rap', 'redneck'\",\n",
      "        b\"'country rap', 'redneck'\"]], dtype=object)>,\n",
      " 'artist_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Redneck Souljers'], dtype=object)>,\n",
      " 'artist_name_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'Redneck Souljers', b'Redneck Souljers', b'Redneck Souljers',\n",
      "        b'Redneck Souljers', b'Redneck Souljers']], dtype=object)>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([41.], dtype=float32)>,\n",
      " 'artist_pop_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[41., 41., 41., 41., 41.]], dtype=float32)>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:artist:5FY8IkeSIChD7WcmPPH5NW'], dtype=object)>,\n",
      " 'artist_uri_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'spotify:artist:5FY8IkeSIChD7WcmPPH5NW',\n",
      "        b'spotify:artist:5FY8IkeSIChD7WcmPPH5NW',\n",
      "        b'spotify:artist:5FY8IkeSIChD7WcmPPH5NW',\n",
      "        b'spotify:artist:5FY8IkeSIChD7WcmPPH5NW',\n",
      "        b'spotify:artist:5FY8IkeSIChD7WcmPPH5NW']], dtype=object)>,\n",
      " 'artists_followers_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[190565., 190565., 190565., 190565., 190565.]], dtype=float32)>,\n",
      " 'candidate_rank': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[5., 4., 3., 2., 1.]], dtype=float32)>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([214134.], dtype=float32)>,\n",
      " 'duration_ms_songs_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[214134., 214134., 214134., 214134., 214134.]], dtype=float32)>,\n",
      " 'num_pl_albums_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.], dtype=float32)>,\n",
      " 'num_pl_artists_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.], dtype=float32)>,\n",
      " 'num_pl_songs_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([15.], dtype=float32)>,\n",
      " 'pl_collaborative_src': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'false'], dtype=object)>,\n",
      " 'pl_duration_ms_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([3514214.], dtype=float32)>,\n",
      " 'pl_name_src': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'staind'], dtype=object)>,\n",
      " 'track_acousticness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0461], dtype=float32)>,\n",
      " 'track_acousticness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.0461, 0.0461, 0.0461, 0.0461, 0.0461]], dtype=float32)>,\n",
      " 'track_danceability_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.681], dtype=float32)>,\n",
      " 'track_danceability_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.681, 0.681, 0.681, 0.681, 0.681]], dtype=float32)>,\n",
      " 'track_energy_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.736], dtype=float32)>,\n",
      " 'track_energy_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.736, 0.736, 0.736, 0.736, 0.736]], dtype=float32)>,\n",
      " 'track_instrumentalness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.68e-05], dtype=float32)>,\n",
      " 'track_instrumentalness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[2.68e-05, 2.68e-05, 2.68e-05, 2.68e-05, 2.68e-05]], dtype=float32)>,\n",
      " 'track_key_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'3.0'], dtype=object)>,\n",
      " 'track_key_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'3.0', b'3.0', b'3.0', b'3.0', b'3.0']], dtype=object)>,\n",
      " 'track_liveness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.078], dtype=float32)>,\n",
      " 'track_liveness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.078, 0.078, 0.078, 0.078, 0.078]], dtype=float32)>,\n",
      " 'track_loudness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-6.485], dtype=float32)>,\n",
      " 'track_loudness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[-6.485, -6.485, -6.485, -6.485, -6.485]], dtype=float32)>,\n",
      " 'track_mode_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'0'], dtype=object)>,\n",
      " 'track_mode_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'0', b'0', b'0', b'0', b'0']], dtype=object)>,\n",
      " 'track_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Down This Road'], dtype=object)>,\n",
      " 'track_name_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'Down This Road', b'Down This Road', b'Down This Road',\n",
      "        b'Down This Road', b'Down This Road']], dtype=object)>,\n",
      " 'track_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([40.], dtype=float32)>,\n",
      " 'track_pop_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[40., 40., 40., 40., 40.]], dtype=float32)>,\n",
      " 'track_speechiness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0437], dtype=float32)>,\n",
      " 'track_speechiness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.0437, 0.0437, 0.0437, 0.0437, 0.0437]], dtype=float32)>,\n",
      " 'track_tempo_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([150.638], dtype=float32)>,\n",
      " 'track_tempo_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[150.638, 150.638, 150.638, 150.638, 150.638]], dtype=float32)>,\n",
      " 'track_time_signature_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'5'], dtype=object)>,\n",
      " 'track_time_signature_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'5', b'5', b'5', b'5', b'5']], dtype=object)>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:track:5kpLMABZF8rvN8UlPxMI4Q'], dtype=object)>,\n",
      " 'track_uri_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'spotify:track:5kpLMABZF8rvN8UlPxMI4Q',\n",
      "        b'spotify:track:5kpLMABZF8rvN8UlPxMI4Q',\n",
      "        b'spotify:track:5kpLMABZF8rvN8UlPxMI4Q',\n",
      "        b'spotify:track:5kpLMABZF8rvN8UlPxMI4Q',\n",
      "        b'spotify:track:5kpLMABZF8rvN8UlPxMI4Q']], dtype=object)>,\n",
      " 'track_valence_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.507], dtype=float32)>,\n",
      " 'track_valence_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.507, 0.507, 0.507, 0.507, 0.507]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for x in valid_parsed.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6031b7e-fcbb-4139-a6c6-75d8a63e6c54",
   "metadata": {},
   "source": [
    "### Train files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f5fc764-c1ca-4346-8fcd-bd9e2939d722",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_files:  ['gs://ndr-v1-myproject32549-bucket/data/v1/train/-00000-of-00022.tfrecords', 'gs://ndr-v1-myproject32549-bucket/data/v1/train/-00001-of-00022.tfrecords', 'gs://ndr-v1-myproject32549-bucket/data/v1/train/-00002-of-00022.tfrecords', 'gs://ndr-v1-myproject32549-bucket/data/v1/train/-00003-of-00022.tfrecords', 'gs://ndr-v1-myproject32549-bucket/data/v1/train/-00004-of-00022.tfrecords', 'gs://ndr-v1-myproject32549-bucket/data/v1/train/-00005-of-00022.tfrecords', 'gs://ndr-v1-myproject32549-bucket/data/v1/train/-00006-of-00022.tfrecords', 'gs://ndr-v1-myproject32549-bucket/data/v1/train/-00007-of-00022.tfrecords', 'gs://ndr-v1-myproject32549-bucket/data/v1/train/-00008-of-00022.tfrecords', 'gs://ndr-v1-myproject32549-bucket/data/v1/train/-00009-of-00022.tfrecords', 'gs://ndr-v1-myproject32549-bucket/data/v1/train/-00010-of-00022.tfrecords', 'gs://ndr-v1-myproject32549-bucket/data/v1/train/-00011-of-00022.tfrecords', 'gs://ndr-v1-myproject32549-bucket/data/v1/train/-00012-of-00022.tfrecords', 'gs://ndr-v1-myproject32549-bucket/data/v1/train/-00013-of-00022.tfrecords', 'gs://ndr-v1-myproject32549-bucket/data/v1/train/-00014-of-00022.tfrecords', 'gs://ndr-v1-myproject32549-bucket/data/v1/train/-00015-of-00022.tfrecords', 'gs://ndr-v1-myproject32549-bucket/data/v1/train/-00016-of-00022.tfrecords', 'gs://ndr-v1-myproject32549-bucket/data/v1/train/-00017-of-00022.tfrecords', 'gs://ndr-v1-myproject32549-bucket/data/v1/train/-00018-of-00022.tfrecords', 'gs://ndr-v1-myproject32549-bucket/data/v1/train/-00019-of-00022.tfrecords', 'gs://ndr-v1-myproject32549-bucket/data/v1/train/-00020-of-00022.tfrecords', 'gs://ndr-v1-myproject32549-bucket/data/v1/train/-00021-of-00022.tfrecords']\n",
      "train size: 111\n"
     ]
    }
   ],
   "source": [
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'data/{DATA_VERSION}/{TRAIN_DIR_PREFIX}/', delimiter=\"/\"):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "print(\"train_files: \", train_files)\n",
    "train = tf.data.TFRecordDataset(train_files)\n",
    "\n",
    "print(f\"train size: {len(list(train))}\")\n",
    "\n",
    "train_parsed = train.map(FEATURE_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f98d42e-4ca6-4e1f-a832-6c0a9b1c44a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec={'album_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'album_name_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'album_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'album_uri_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artist_followers_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'artist_genres_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_genres_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artist_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_name_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artist_pop_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'artist_pop_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'artist_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_uri_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artists_followers_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'candidate_rank': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'duration_ms_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'duration_ms_songs_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'num_pl_albums_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'num_pl_artists_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'num_pl_songs_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'pl_collaborative_src': TensorSpec(shape=(), dtype=tf.string, name=None), 'pl_duration_ms_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'pl_name_src': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_acousticness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_acousticness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_danceability_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_danceability_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_energy_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_energy_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_instrumentalness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_instrumentalness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_key_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_key_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_liveness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_liveness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_loudness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_loudness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_mode_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_mode_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_name_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_pop_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_pop_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_speechiness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_speechiness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_tempo_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_tempo_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_time_signature_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_time_signature_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_uri_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_valence_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_valence_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b4a2ecb-0255-4b67-afe5-13659a6921f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'The Best of Mandy Moore'], dtype=object)>, 'album_name_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'The Best of Mandy Moore', b'The Best of Mandy Moore',\n",
      "        b'The Best of Mandy Moore', b'The Best of Mandy Moore',\n",
      "        b'The Best of Mandy Moore']], dtype=object)>, 'album_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:album:551186Jr75bHrh58ZdEMhW'], dtype=object)>, 'album_uri_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'spotify:album:551186Jr75bHrh58ZdEMhW',\n",
      "        b'spotify:album:551186Jr75bHrh58ZdEMhW',\n",
      "        b'spotify:album:551186Jr75bHrh58ZdEMhW',\n",
      "        b'spotify:album:551186Jr75bHrh58ZdEMhW',\n",
      "        b'spotify:album:551186Jr75bHrh58ZdEMhW']], dtype=object)>, 'artist_followers_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([724908.], dtype=float32)>, 'artist_genres_can': <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b\"'dance pop', 'hollywood', 'neo mellow', 'post-teen pop'\"],\n",
      "      dtype=object)>, 'artist_genres_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b\"'dance pop', 'hollywood', 'neo mellow', 'post-teen pop'\",\n",
      "        b\"'dance pop', 'hollywood', 'neo mellow', 'post-teen pop'\",\n",
      "        b\"'dance pop', 'hollywood', 'neo mellow', 'post-teen pop'\",\n",
      "        b\"'dance pop', 'hollywood', 'neo mellow', 'post-teen pop'\",\n",
      "        b\"'dance pop', 'hollywood', 'neo mellow', 'post-teen pop'\"]],\n",
      "      dtype=object)>, 'artist_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Mandy Moore'], dtype=object)>, 'artist_name_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'Mandy Moore', b'Mandy Moore', b'Mandy Moore', b'Mandy Moore',\n",
      "        b'Mandy Moore']], dtype=object)>, 'artist_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([64.], dtype=float32)>, 'artist_pop_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[64., 64., 64., 64., 64.]], dtype=float32)>, 'artist_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:artist:2LJxr7Pt3JnP60eLxwbDOu'], dtype=object)>, 'artist_uri_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'spotify:artist:2LJxr7Pt3JnP60eLxwbDOu',\n",
      "        b'spotify:artist:2LJxr7Pt3JnP60eLxwbDOu',\n",
      "        b'spotify:artist:2LJxr7Pt3JnP60eLxwbDOu',\n",
      "        b'spotify:artist:2LJxr7Pt3JnP60eLxwbDOu',\n",
      "        b'spotify:artist:2LJxr7Pt3JnP60eLxwbDOu']], dtype=object)>, 'artists_followers_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[724908., 724908., 724908., 724908., 724908.]], dtype=float32)>, 'candidate_rank': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[5., 4., 3., 2., 1.]], dtype=float32)>, 'duration_ms_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([233680.], dtype=float32)>, 'duration_ms_songs_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[233680., 233680., 233680., 233680., 233680.]], dtype=float32)>, 'num_pl_albums_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'num_pl_artists_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, 'num_pl_songs_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([5.], dtype=float32)>, 'pl_collaborative_src': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'false'], dtype=object)>, 'pl_duration_ms_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1168400.], dtype=float32)>, 'pl_name_src': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'\\xf0\\x9f\\x98\\xb4\\xf0\\x9f\\x92\\xa4'], dtype=object)>, 'track_acousticness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.856], dtype=float32)>, 'track_acousticness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.856, 0.856, 0.856, 0.856, 0.856]], dtype=float32)>, 'track_danceability_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.45], dtype=float32)>, 'track_danceability_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.45, 0.45, 0.45, 0.45, 0.45]], dtype=float32)>, 'track_energy_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.294], dtype=float32)>, 'track_energy_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.294, 0.294, 0.294, 0.294, 0.294]], dtype=float32)>, 'track_instrumentalness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([8.41e-06], dtype=float32)>, 'track_instrumentalness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[8.41e-06, 8.41e-06, 8.41e-06, 8.41e-06, 8.41e-06]], dtype=float32)>, 'track_key_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'8.0'], dtype=object)>, 'track_key_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'8.0', b'8.0', b'8.0', b'8.0', b'8.0']], dtype=object)>, 'track_liveness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.126], dtype=float32)>, 'track_liveness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.126, 0.126, 0.126, 0.126, 0.126]], dtype=float32)>, 'track_loudness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-9.463], dtype=float32)>, 'track_loudness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[-9.463, -9.463, -9.463, -9.463, -9.463]], dtype=float32)>, 'track_mode_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'0'], dtype=object)>, 'track_mode_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'0', b'0', b'0', b'0', b'0']], dtype=object)>, 'track_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Only Hope'], dtype=object)>, 'track_name_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'Only Hope', b'Only Hope', b'Only Hope', b'Only Hope',\n",
      "        b'Only Hope']], dtype=object)>, 'track_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([55.], dtype=float32)>, 'track_pop_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[55., 55., 55., 55., 55.]], dtype=float32)>, 'track_speechiness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0269], dtype=float32)>, 'track_speechiness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.0269, 0.0269, 0.0269, 0.0269, 0.0269]], dtype=float32)>, 'track_tempo_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([80.272], dtype=float32)>, 'track_tempo_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[80.272, 80.272, 80.272, 80.272, 80.272]], dtype=float32)>, 'track_time_signature_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'4'], dtype=object)>, 'track_time_signature_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'4', b'4', b'4', b'4', b'4']], dtype=object)>, 'track_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:track:6dOzblcXKWBpZt6uGwC8z8'], dtype=object)>, 'track_uri_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'spotify:track:6dOzblcXKWBpZt6uGwC8z8',\n",
      "        b'spotify:track:6dOzblcXKWBpZt6uGwC8z8',\n",
      "        b'spotify:track:6dOzblcXKWBpZt6uGwC8z8',\n",
      "        b'spotify:track:6dOzblcXKWBpZt6uGwC8z8',\n",
      "        b'spotify:track:6dOzblcXKWBpZt6uGwC8z8']], dtype=object)>, 'track_valence_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.234], dtype=float32)>, 'track_valence_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.234, 0.234, 0.234, 0.234, 0.234]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for x in train_parsed.batch(1).take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146c17ea-9381-439c-aebe-665e6d9fb7ac",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-8:m119"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
